{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math as mt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## given $\\textbf{p}, \\textbf{q} \\in \\mathbb{R}^{d}$ \n",
    "\n",
    "### $$\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    \\text{linear_module_up } : \\mathcal{L}^{up}\\begin{pmatrix}\n",
    "    \\textbf{p} \\\\\n",
    "    \\textbf{q}\n",
    "    \\end{pmatrix} &= \\begin{pmatrix}\n",
    "    I & S\\\\\n",
    "    0 & I\n",
    "    \\end{pmatrix} \\begin{pmatrix}\n",
    "    \\textbf{p} \\\\\n",
    "    \\textbf{q}\n",
    "    \\end{pmatrix} \\\\\n",
    "    \\text{linear_module_low } : \\mathcal{L}^{low}\\begin{pmatrix}\n",
    "    \\textbf{p} \\\\\n",
    "    \\textbf{q}\n",
    "    \\end{pmatrix} &= \\begin{pmatrix}\n",
    "    I & 0\\\\\n",
    "    S & I\n",
    "    \\end{pmatrix} \\begin{pmatrix}\n",
    "    \\textbf{p} \\\\\n",
    "    \\textbf{q}\n",
    "    \\end{pmatrix},\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "## where $S \\in \\mathbb{R}^{d \\times d}$ is symmetric.\n",
    "\n",
    "### $$\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    \\text{activation_module_up } : \\mathcal{N}^{up}\\begin{pmatrix}\n",
    "    \\textbf{p} \\\\\n",
    "    \\textbf{q}\n",
    "    \\end{pmatrix} &= \\begin{bmatrix}\n",
    "    I & \\sigma_{\\textbf{a}}\\\\\n",
    "    0 & I\n",
    "    \\end{bmatrix} \\begin{pmatrix}\n",
    "    \\textbf{p} \\\\\n",
    "    \\textbf{q}\n",
    "    \\end{pmatrix} := \\begin{pmatrix}\n",
    "    diag(\\textbf{a})\\sigma(\\textbf{q}) + \\textbf{p}\\\\\n",
    "    \\textbf{q}\n",
    "    \\end{pmatrix}\\\\\n",
    "    \\text{activation_module_low } : \\mathcal{N}^{low}\\begin{pmatrix}\n",
    "    \\textbf{p}\\\\\n",
    "    \\textbf{q}\n",
    "    \\end{pmatrix} &= \\begin{bmatrix}\n",
    "    I & 0 \\\\\n",
    "    \\sigma_{\\textbf{a}} & I\n",
    "    \\end{bmatrix} \\begin{pmatrix}\n",
    "    \\textbf{p} \\\\\n",
    "    \\textbf{q}\n",
    "    \\end{pmatrix} := \\begin{pmatrix}\n",
    "    \\textbf{p} \\\\\n",
    "    diag(\\textbf{a})\\sigma(\\textbf{p}) + \\textbf{q}\n",
    "    \\end{pmatrix},\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "## where $\\sigma$ acts element-wise. The parameters are $S$ and $\\textbf{a}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_module_up(layers.Layer):\n",
    "    \n",
    "    def __init__(self, bias):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.w = self.add_weight(\n",
    "        name='w',\n",
    "        shape=(2,2),\n",
    "        initializer = 'random_normal',\n",
    "        trainable = True\n",
    "        )\n",
    "    \n",
    "        if bias==1:\n",
    "            self.b = self.add_weight(\n",
    "            name='b',\n",
    "            shape=(4,),\n",
    "            initializer = 'random_normal',\n",
    "            trainable = True\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            self.b = tf.constant([0., 0., 0., 0.])\n",
    "\n",
    "    def call(self, x):\n",
    "        \n",
    "        L11 = tf.concat([[[1.,0.],[1.,1.]]], 0)\n",
    "        L12 = self.w + tf.transpose(self.w)\n",
    "        L21 = tf.concat([[[0.,0.],[0.,0.]]],0)\n",
    "        L22 = tf.concat([[[1.,0.],[0.,1.]]],0)\n",
    "\n",
    "        L = tf.concat([tf.concat([L11,L12], 1), tf.concat([L21,L22], 1)], 0)\n",
    "        \n",
    "        return tf.linalg.matvec(L,x) + self.b\n",
    "\n",
    "class linear_module_low(layers.Layer):\n",
    "    \n",
    "    def __init__(self, bias):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.w = self.add_weight(\n",
    "        name='w',\n",
    "        shape=(2,2),\n",
    "        initializer = 'random_normal',\n",
    "        trainable = True\n",
    "        )\n",
    "\n",
    "        if bias==1:\n",
    "            self.b = self.add_weight(\n",
    "            name='b',\n",
    "            shape=(4,),\n",
    "            initializer = 'random_normal',\n",
    "            trainable = True\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            self.b = tf.constant([0., 0., 0., 0.])\n",
    "\n",
    "    def call(self, x):\n",
    "        \n",
    "        L11 = tf.concat([[[1.,0.],[1.,1.]]], 0)\n",
    "        L12 = tf.concat([[[0.,0.],[0.,0.]]],0) \n",
    "        L21 = self.w + tf.transpose(self.w)\n",
    "        L22 = tf.concat([[[1.,0.],[0.,1.]]],0)\n",
    "\n",
    "        L = tf.concat([tf.concat([L11,L12], 1), tf.concat([L21,L22], 1)], 0)\n",
    "        \n",
    "        return tf.linalg.matvec(L,x) + self.b\n",
    "\n",
    "\n",
    "class activation_module_up(layers.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.w = self.add_weight(\n",
    "        name='w',\n",
    "        shape=(2,),\n",
    "        initializer = 'random_normal',\n",
    "        trainable = True\n",
    "        )\n",
    "        \n",
    "    def tanh(self, x):\n",
    "        \n",
    "        return tf.where([True, True, False, False], tf.math.tanh(elem), elem)\n",
    "\n",
    "\n",
    "    def call(self, x):        \n",
    "        t = tf.concat([[[0.,0.,self.w[0], 0.]], [[0.,0.,0., self.w[1]]], [[0.,0.,0.,0.]], [[0.,0.,0.,0.]]], 0)\n",
    "        \n",
    "        return x + tf.linalg.matvec(t, tf.math.tanh(x))\n",
    "\n",
    "class activation_module_low(layers.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.w = self.add_weight(\n",
    "        name='w',\n",
    "        shape=(2,),\n",
    "        initializer = 'random_normal',\n",
    "        trainable = True\n",
    "        )\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        t = tf.concat([[[0.,0.,0.,0.]], [[0.,0.,0.,0.]], [[self.w[0],0.,0.,0.]], [[0.,self.w[1],0.,0.]]],0)\n",
    "        \n",
    "        return x + tf.linalg.matvec(t, tf.math.tanh(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$\\text{SympNet : } \\phi = L_{1} L_{2} \\dots L_{5} \\text{  } A_{1} \\text{  } L_{6} \\dots L_{10} \\text{  } A_{2} \\dots $$\n",
    "\n",
    "## A bias $\\textbf{b} \\in \\mathbb{R}^{2d}$ is added at the end of every sequence of linear modules as:\n",
    "\n",
    "## $$\\begin{equation}\n",
    "    \\begin{pmatrix}\n",
    "    I & 0/S_{n}\\\\\n",
    "    S_{n}/0 & I\n",
    "    \\end{pmatrix} \\dots \\begin{pmatrix}\n",
    "    I & 0 \\\\\n",
    "    S_{2} & I\n",
    "    \\end{pmatrix} \\begin{pmatrix}\n",
    "    I & S_{1} \\\\\n",
    "    0 & I\n",
    "    \\end{pmatrix} \\begin{pmatrix}\n",
    "    \\textbf{q} \\\\\n",
    "    \\textbf{p}\n",
    "    \\end{pmatrix} + \\textbf{b},\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SympNet(keras.Model):\n",
    "    \n",
    "    def __init__(self, N_layers, N_sub):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.Modules = []\n",
    "        ind = [0]\n",
    "        \n",
    "        for i in range(N_layers):\n",
    "            \n",
    "            if i%2==0:\n",
    "                self.Modules.append(activation_module_up())\n",
    "                ind.append(ind[-1]+2)\n",
    "                \n",
    "            else:\n",
    "                self.Modules.append(activation_module_low())\n",
    "                ind.append(ind[-1]+2)\n",
    "                \n",
    "            for j in range(N_sub):\n",
    "                \n",
    "                if j==(N_sub-1):\n",
    "                    bias = 1\n",
    "                else:\n",
    "                    bias = 0\n",
    "                \n",
    "                if j%2==0:\n",
    "                    self.Modules.append(linear_module_up(bias))\n",
    "                    ind.append(ind[-1]+3)\n",
    "\n",
    "                else:\n",
    "                    self.Modules.append(linear_module_low(bias))\n",
    "                    ind.append(ind[-1]+3)\n",
    "        \n",
    "        \n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        \n",
    "        boom = self.Modules[0](input_tensor)\n",
    "        \n",
    "        for i in range(1,len(self.Modules)):\n",
    "            boom = self.Modules[i](boom)\n",
    "    \n",
    "        return boom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 = [1.5707963267948966, 1.566239991721592, 1.5525684142348404, 1.5297663397106285, 1.4977887927324212, 1.4565366561292123, 1.4058216571667934, 1.345315288418439, 1.2744749942705154, 1.192439405188996, 1.0978902204838283, 0.98893637750854, 0.863313832998702, 0.719979121128513, 0.5634707786673293, 0.40553835276492617, 0.2559015136168972, 0.11677369940421105, -0.01321349868486478, -0.135720559123984, -0.25173070244922685, -0.36143329122506257, -0.4643125934786468, -0.5592884560948824, -0.644880314285508, -0.7193799988602931, -0.7810102666568061, -0.8280354546553392, -0.8587967047942946, -0.8716537869529154, -0.8648494212646399, -0.8364294647245307, -0.7848184226611568, -0.7118531784049053, -0.6282566914142615, -0.5496432175219048, -0.48378730823347227, -0.43059859794700867, -0.38763940679069536, -0.3524414108302813, -0.32293721425987787, -0.29742786963772566, -0.27449044610855455, -0.2529046489556837, -0.23160512888980855, -0.20965387897265564, -0.18622676419662065, -0.16061022119489357, -0.13220512931034253, -0.10053601348320118, -0.06526290871104996, -0.026194059301420505, 0.016703494797548218, 0.06329829988706372, 0.11329605260636114, 0.1662483434154595, 0.22157045885723953, 0.2785609263020437, 0.33642631125851125, 0.3942999798562905]\n",
    "q1 = [0.0, -0.30376435126781104, -0.6077495434555871, -0.9126254586263232, -1.219741879215434, -1.531417768449487, -1.8513689853576767, -2.1853459514332036, -2.5420424275635978, -2.934241774571085, -3.3795821838320097, -3.8972786273402993, -4.486024368096188, -5.046956533004935, -5.3142538255761975, -5.157279970634232, -4.8096328823693675, -4.474894873856334, -4.20054506421623, -3.972079185761887, -3.762924758053701, -3.547637153301479, -3.3048914147739805, -3.0185089869838126, -2.6780302031642123, -2.278679221184974, -1.8203439962909433, -1.305486653614162, -0.7362323461572511, -0.11121907409073595, 0.5758801678640377, 1.3289861424902814, 2.1057365044064102, 2.697742173636928, 2.7778228427218665, 2.421813243485241, 1.9726616801625438, 1.587834815789564, 1.2899652308515905, 1.0680124926761954, 0.9083173419683229, 0.8001701156374053, 0.7357452330142118, 0.7092122893314955, 0.7159596120077603, 0.7520336194179128, 0.8137407260256012, 0.8973632893951299, 0.9989569706873678, 1.1142134007270805, 1.2383988841867644, 1.3663768008960533, 1.4927292140820765, 1.6119521256211122, 1.718727775019843, 1.808171238165814, 1.8760532029964878, 1.918897567827292, 1.9339664516211645, 1.9191513478646356]\n",
    "p0 = [0.0, 0.015010661596500906, 0.03016838349607194, 0.045849241601727375, 0.06268166688933882, 0.08155334769256958, 0.1036261438314411, 0.13036517471286946, 0.163590343668514, 0.205559669379517, 0.25908246937914287, 0.32757747885354793, 0.41464255598143124, 0.5215931221289993, 0.6410643032666817, 0.7546768209119165, 0.8465216690410882, 0.9115053436365511, 0.9501714651556946, 0.964227166866312, 0.9553048391110284, 0.924904554372447, 0.8745573812136203, 0.8059436672175694, 0.7209031441680881, 0.6213356178089464, 0.5090125952507778, 0.3853359171163647, 0.2510727118868576, 0.1060785506508933, -0.05097032245808686, -0.22270364368715354, -0.41229167844354564, -0.6193269498161159, -0.8320983557538961, -1.0322069201702464, -1.2110676594970053, -1.369735874550352, -1.511662327902453, -1.6398415956467602, -1.756414849050924, -1.8628213799574547, -1.9599887192601533, -2.0484763105169517, -2.128575170247076, -2.200377006101112, -2.263825181161412, -2.3187552214993925, -2.364930076806055, -2.402074913767808, -2.429911304591378, -2.448191102772614, -2.4567287879972306, -2.455426813912845, -2.44429361775101, -2.4234497495161733, -2.393123006575751, -2.3536363938681677, -2.305389463564221, -2.2488430195610345]\n",
    "p1 = [0.5, 0.5014122198164906, 0.5111906410035314, 0.5376876256736828, 0.5893974749064902, 0.6751534377734025, 0.8044795691506748, 0.9881879083083701, 1.2392987580606556, 1.5742062960468985, 2.0131070034033582, 2.574312554731744, 3.241254718230227, 3.851520233340414, 4.000388645475294, 3.480353172035228, 2.618984378334507, 1.718652702955221, 0.8690673681519698, 0.0770189111114476, -0.6636138645097251, -1.3546350172552513, -1.9925133049403287, -2.5714568073703545, -3.087244424145427, -3.54061625555913, -3.9396551172397047, -4.301033141631248, -4.650493711146786, -5.023031241706978, -5.4617424865174335, -6.006704548681564, -6.636047860083942, -7.099996182944599, -6.968383419052819, -6.32721424951262, -5.607376674196277, -4.990916159914383, -4.487574403168241, -4.069493435935189, -3.7099432905399996, -3.38889931230865, -3.0919779687550126, -2.808775538309371, -2.5316288786200154, -2.254823032471658, -1.9741236304447236, -1.6865408931448582, -1.3902378804194453, -1.084519631778824, -0.7698408896427894, -0.44776986935769314, -0.12085470223367972, 0.20760836746941957, 0.5339318524324353, 0.8543906184453571, 1.1655832102649064, 1.4646334851920972, 1.7492574706100827, 2.017678639340289]\n",
    "\n",
    "X = []\n",
    "for i in zip(p0, p1, q0, q1):\n",
    "    X.append([[i[0],i[1],i[2],i[3]]])\n",
    "\n",
    "x_train = np.array(X[:len(X)-1])\n",
    "y_train = np.array(X[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model + training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SympNet(8, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss= tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(), #, clipvalue = 0.001),\n",
    "    #optimizer=keras.optimizers.SGD(0.00001), #, clipvalue = 0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1razbqd9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21728<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bf69b113d148f3b1fe6ae3d6178f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\valpe\\Documents\\GitHub\\ML_DynamicalSystems\\ML_Differential_Equations\\Code\\TensorFlow\\Learning Hamiltonian Dynamics\\GPU_friendly\\wandb\\run-20210201_135709-1razbqd9\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\valpe\\Documents\\GitHub\\ML_DynamicalSystems\\ML_Differential_Equations\\Code\\TensorFlow\\Learning Hamiltonian Dynamics\\GPU_friendly\\wandb\\run-20210201_135709-1razbqd9\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">solar-frog-3</strong>: <a href=\"https://wandb.ai/riccardovalperga/uncategorized/runs/1razbqd9\" target=\"_blank\">https://wandb.ai/riccardovalperga/uncategorized/runs/1razbqd9</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1razbqd9). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.15<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">chocolate-totem-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/riccardovalperga/uncategorized\" target=\"_blank\">https://wandb.ai/riccardovalperga/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/riccardovalperga/uncategorized/runs/137tpw62\" target=\"_blank\">https://wandb.ai/riccardovalperga/uncategorized/runs/137tpw62</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\valpe\\Documents\\GitHub\\ML_DynamicalSystems\\ML_Differential_Equations\\Code\\TensorFlow\\Learning Hamiltonian Dynamics\\GPU_friendly\\wandb\\run-20210201_135757-137tpw62</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "59/59 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 2/300\n",
      "59/59 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 3/300\n",
      "59/59 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 4/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 5/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 6/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 7/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 8/300\n",
      "59/59 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 9/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 10/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 11/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 12/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 13/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 14/300\n",
      "59/59 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 15/300\n",
      "59/59 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 16/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 17/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 18/300\n",
      "59/59 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 19/300\n",
      "59/59 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 20/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 21/300\n",
      "59/59 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 22/300\n",
      "59/59 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 23/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 24/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 25/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 26/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 27/300\n",
      "59/59 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 28/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 29/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 30/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 31/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 32/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 33/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 34/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 35/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 36/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 37/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 38/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 39/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 40/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 41/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 42/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 43/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 44/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 45/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 46/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 47/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 48/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 49/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 50/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 51/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 52/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 53/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 54/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 55/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 56/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 57/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 58/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 59/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 60/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 61/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 62/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 63/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 64/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 65/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 66/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 67/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 68/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 69/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 70/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 71/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 72/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 73/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034: 0s - loss: nan - accur\n",
      "Epoch 74/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 75/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034: 0s - loss: nan - accuracy: \n",
      "Epoch 76/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 77/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 78/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 79/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 80/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 81/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 82/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 83/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 84/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 85/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 86/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 87/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 88/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 89/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 90/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 91/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034ETA: 0s - loss: nan - ac\n",
      "Epoch 92/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 93/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 94/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 95/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 96/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 97/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 98/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 99/300\n",
      "59/59 [==============================] - 1s 17ms/step - loss: nan - accuracy: 0.2034\n",
      "Epoch 100/300\n",
      "59/59 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.2034: 0s - loss: nan - accur\n",
      "Epoch 101/300\n",
      "19/59 [========>.....................] - ETA: 0s - loss: nan - accuracy: 0.1579   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-1252e779bc66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"running time : %s seconds\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \"\"\"\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \"\"\"\n\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#wandb.init()\n",
    "\n",
    "start_time = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=1, epochs=300, verbose=1)\n",
    "print(\"running time : %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_test = 30\n",
    "\n",
    "p = [model(x_train[0][0])[0]]\n",
    "pp = [model(x_train[0][0])[1]]\n",
    "\n",
    "q = [model(x_train[0][0])[2]]\n",
    "qq = [model(x_train[0][0])[3]]\n",
    "\n",
    "run = [model(X[0][0])]\n",
    "\n",
    "for i in range(N_test):\n",
    "    run.append(model(run[-1]))\n",
    "    p.append(run[-1][0])\n",
    "    pp.append(run[-1][1])\n",
    "    q.append(run[-1][2])\n",
    "    qq.append(run[-1][3])\n",
    "\n",
    "\n",
    "plt.plot(q, p, color = \"r\", label = \"learned\")\n",
    "plt.plot(q0, p0, color = \"b\", label = \"true\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
